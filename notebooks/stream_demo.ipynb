{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import matplotlib.mlab as mlab\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from queue import Queue\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_DURATION_MS = 5000\n",
    "N_SAMPLES = 300\n",
    "\n",
    "KERNEL_SIZE = 15\n",
    "STRIDE = 4\n",
    "FRAME_RATE = 48000\n",
    "NFFT = 512\n",
    "TX = int(FRAME_RATE * 0.0195)\n",
    "FX = int(NFFT / 2) + 1\n",
    "TY = round((TX - KERNEL_SIZE + STRIDE) / STRIDE)\n",
    "\n",
    "MULTRIGGER_MODE = False\n",
    "\n",
    "if MULTRIGGER_MODE:\n",
    "    N_CLASSES = len({Path(k).parent for k in glob.glob(\"{}/positives/*/*.wav\".format(RAW_DATA_DIR))}) + 1\n",
    "else:\n",
    "    N_CLASSES = 2\n",
    "\n",
    "\n",
    "CHUNK_DURATION = 0.5 # Each read length in seconds from mic.\n",
    "FS = 48000 # sampling rate for mic\n",
    "CHUNK_SAMPLES = int(FS * CHUNK_DURATION) # Each read length in number of samples.\n",
    "\n",
    "# Each model input data duration in seconds, need to be an integer numbers of chunk_duration\n",
    "FEED_DURATION = 5\n",
    "FEED_SAMPLES = int(FS * FEED_DURATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def seq_model(input_shape, n_classes, kernel_size, stride):\n",
    "    \"\"\"\n",
    "    Function creating the model's graph in Keras.\n",
    "\n",
    "    :param input_shape: shape of the model's input data (using Keras conventions)\n",
    "    :param n_classes: n_classes to predict for the last dense layer\n",
    "    :param kernel_size: kernel size of the first conv layer\n",
    "    :param stride : stride_size of the first conv layer\n",
    "    :return: Keras model instance\n",
    "    \"\"\"\n",
    "\n",
    "    X_input = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    # Step 1: CONV layer (≈4 lines)\n",
    "    X = tf.keras.layers.Conv1D(256, kernel_size=kernel_size, strides=stride)(X_input)  # CONV1D\n",
    "    X = tf.keras.layers.BatchNormalization()(X)  # Batch normalization\n",
    "    X = tf.keras.layers.Activation('relu')(X)  # ReLu activation\n",
    "    X = tf.keras.layers.Dropout(0.1)(X)  # dropout (use 0.8)\n",
    "\n",
    "    # Step 2: First GRU Layer (≈4 lines)\n",
    "    X = tf.keras.layers.GRU(units=256, return_sequences=True)(X)  # GRU (use 128 units and return the sequences)\n",
    "    X = tf.keras.layers.Dropout(0.1)(X)  # dropout (use 0.8)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)  # Batch normalization\n",
    "\n",
    "    # Step 3: Second GRU Layer (≈4 lines)\n",
    "    X = tf.keras.layers.GRU(units=256, return_sequences=True)(X)  # GRU (use 128 units and return the sequences)\n",
    "    X = tf.keras.layers.Dropout(0.1)(X)  # dropout (use 0.8)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)  # Batch normalization\n",
    "\n",
    "    # Step 4: Time-distributed dense layer (≈1 line)\n",
    "    X = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_classes, activation=\"softmax\"))(X)  # time distributed  (sigmoid)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=X_input, outputs=X)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(weights_dir):\n",
    "    \"\"\"\n",
    "    Load our seq_model with the latest checkpoint\n",
    "    :param weights_dir: directory where we have our checkpoints from our training\n",
    "    :return: our sequence model with weights\n",
    "    \"\"\"\n",
    "    latest = tf.train.latest_checkpoint(str(weights_dir))\n",
    "    print(latest)\n",
    "    model = seq_model(input_shape=(TX, FX),\n",
    "                      n_classes=N_CLASSES,\n",
    "                      kernel_size=KERNEL_SIZE,\n",
    "                      stride=STRIDE)\n",
    "\n",
    "    model.load_weights(latest)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../logs/checkpoints/cp-0020.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0806 11:29:57.787000 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer\n",
      "W0806 11:29:57.788345 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer.iter\n",
      "W0806 11:29:57.789480 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "W0806 11:29:57.790293 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "W0806 11:29:57.791121 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer.decay\n",
      "W0806 11:29:57.792778 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "W0806 11:29:57.793840 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
      "W0806 11:29:57.794796 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
      "W0806 11:29:57.795711 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.gamma\n",
      "W0806 11:29:57.796384 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.beta\n",
      "W0806 11:29:57.797018 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.gamma\n",
      "W0806 11:29:57.797705 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.beta\n",
      "W0806 11:29:57.798318 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-5.gamma\n",
      "W0806 11:29:57.800316 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-5.beta\n",
      "W0806 11:29:57.801242 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.kernel\n",
      "W0806 11:29:57.802021 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "W0806 11:29:57.802512 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.bias\n",
      "W0806 11:29:57.803196 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.cell.kernel\n",
      "W0806 11:29:57.803963 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.cell.recurrent_kernel\n",
      "W0806 11:29:57.805948 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.cell.bias\n",
      "W0806 11:29:57.807011 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-6.layer.kernel\n",
      "W0806 11:29:57.808794 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-6.layer.bias\n",
      "W0806 11:29:57.809651 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
      "W0806 11:29:57.810979 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
      "W0806 11:29:57.811722 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.gamma\n",
      "W0806 11:29:57.812631 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.beta\n",
      "W0806 11:29:57.815360 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.gamma\n",
      "W0806 11:29:57.816385 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.beta\n",
      "W0806 11:29:57.817489 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-5.gamma\n",
      "W0806 11:29:57.818353 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-5.beta\n",
      "W0806 11:29:57.820602 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.kernel\n",
      "W0806 11:29:57.821520 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "W0806 11:29:57.822313 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.bias\n",
      "W0806 11:29:57.822992 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.cell.kernel\n",
      "W0806 11:29:57.823765 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.cell.recurrent_kernel\n",
      "W0806 11:29:57.824658 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.cell.bias\n",
      "W0806 11:29:57.825716 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-6.layer.kernel\n",
      "W0806 11:29:57.828990 140734794945984 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-6.layer.bias\n",
      "W0806 11:29:57.829892 140734794945984 util.py:252] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"../logs/checkpoints/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_input_stream(callback):\n",
    "    stream = pyaudio.PyAudio().open(\n",
    "        format=pyaudio.paInt16,\n",
    "        channels=1,\n",
    "        rate=FS,\n",
    "        input=True,\n",
    "        frames_per_buffer=CHUNK_SAMPLES,\n",
    "        input_device_index=0,\n",
    "        stream_callback=callback)\n",
    "    return stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(data, fs=2):\n",
    "    \"\"\"\n",
    "    Function to compute a spectrogram.\n",
    "    :param data: one channel / dual channel audio data as numpy array\n",
    "    :return: spectrogram, 2-D array, columns are the periodograms of successive segments.\n",
    "    \"\"\"\n",
    "\n",
    "    noverlap = 256\n",
    "    nchannels = data.ndim\n",
    "    if nchannels == 1:\n",
    "        pxx, _, _ = mlab.specgram(data, NFFT, fs, noverlap=noverlap)\n",
    "    elif nchannels == 2:\n",
    "        pxx, _, _ = mlab.specgram(data[:, 0], NFFT, fs, noverlap=noverlap)\n",
    "\n",
    "    return np.swapaxes(pxx, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 936, 257)]        0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 231, 256)          987136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 231, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 231, 256)          0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 231, 256)          0         \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 231, 256)          393984    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 231, 256)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 231, 256)          1024      \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (None, 231, 256)          393984    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 231, 256)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 231, 256)          1024      \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 231, 2)            514       \n",
      "=================================================================\n",
      "Total params: 1,778,690\n",
      "Trainable params: 1,777,154\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_triggerword_spectrum(model, x):\n",
    "    \"\"\"\n",
    "    Function to predict the location of the trigger word.\n",
    "\n",
    "    :param model: neural network that is use for inference\n",
    "    :param x: spectrum of shape (TX, FX)\n",
    "    :return: predictions -- numpy ndarray to shape (number of output time steps per num_classes)\n",
    "    \"\"\"\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    predictions = model.predict(x)\n",
    "    return predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_new_triggerword(predictions, chunk_duration, feed_duration, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Function to detect new trigger word in the latest chunk of input audio.\n",
    "    It is looking for the rising edge of the predictions data belongs to the\n",
    "    last/latest chunk.\n",
    "\n",
    "    :param predictions:  predicted labels from model\n",
    "    :param chunk_duration: time in second of a chunk\n",
    "    :param feed_duration: time in second of the input to model\n",
    "    :param threshold: threshold for probability above a certain to be considered positive\n",
    "    :return: True if new trigger word detected in the latest chunk\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = predictions[:,1] > threshold\n",
    "    chunk_predictions_samples = int(len(predictions) * chunk_duration / feed_duration)\n",
    "    chunk_predictions = predictions[-chunk_predictions_samples:]\n",
    "    level = chunk_predictions[0]\n",
    "    for pred in chunk_predictions:\n",
    "        if pred > level:\n",
    "            return True\n",
    "        else:\n",
    "            level = pred\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---.0.008725041\n",
      "-.0.0022164478\n",
      ".0.0037720846\n",
      ".0.0068239453\n",
      ".0.00038079498\n",
      "--------.0.0060485685\n",
      ".0.024215013\n",
      "-----.1.0\n",
      "1.0.020444132\n",
      "----.0.0055989707\n",
      ".0.0040698904\n",
      ".0.0031244028\n",
      ".0.0046375897\n",
      "-.0.006597542\n",
      "---.0.006719475\n",
      ".0.005733959\n",
      ".0.0077943127\n",
      "----------"
     ]
    }
   ],
   "source": [
    "# Queue to communiate between the audio callback and main thread\n",
    "q = Queue()\n",
    "\n",
    "run = True\n",
    "\n",
    "silence_threshold = 100\n",
    "\n",
    "# Run the demo for a timeout seconds\n",
    "timeout = time.time() + 0.5*60  # 0.5 minutes from now\n",
    "\n",
    "# Data buffer for the input wavform\n",
    "data = np.zeros(FEED_SAMPLES, dtype='int16')\n",
    "\n",
    "def callback(in_data, frame_count, time_info, status):\n",
    "    global run, timeout, data, silence_threshold    \n",
    "    if time.time() > timeout:\n",
    "        run = False        \n",
    "    data0 = np.frombuffer(in_data, dtype='int16')\n",
    "    if np.abs(data0).mean() < silence_threshold:\n",
    "        sys.stdout.write('-')\n",
    "        return (in_data, pyaudio.paContinue)\n",
    "    else:\n",
    "        sys.stdout.write('.')\n",
    "    data = np.append(data,data0)    \n",
    "    if len(data) > FEED_SAMPLES:\n",
    "        data = data[-FEED_SAMPLES:]\n",
    "        # Process data async by sending a queue.\n",
    "        q.put(data)\n",
    "    return (in_data, pyaudio.paContinue)\n",
    "\n",
    "stream = get_audio_input_stream(callback)\n",
    "stream.start_stream()\n",
    "\n",
    "try:\n",
    "    while run:\n",
    "        data = q.get()\n",
    "        spectrum = get_spectrogram(data)\n",
    "        preds = detect_triggerword_spectrum(model, spectrum)\n",
    "        print(preds[-1,1])\n",
    "        new_trigger = has_new_triggerword(preds, CHUNK_DURATION, FEED_DURATION)\n",
    "        if new_trigger:\n",
    "            sys.stdout.write('1')\n",
    "except (KeyboardInterrupt, SystemExit):\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    timeout = time.time()\n",
    "    run = False\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.stop_stream()\n",
    "stream.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
